# -*- coding: utf-8 -*-
"""deepwalk.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rpUvFE02KUXX1QZGaCOU-Td12x7b3A3H

https://www.kaggle.com/code/fellahabdelnour13/deepwalk-from-scratch - o sa incerc asta prima oara

also: https://www.geeksforgeeks.org/machine-learning/deepwalk-algorithm/

poate helpful??? https://www.kaggle.com/code/midnitekoder/covid-19-citation-graph-embedding-using-deepwalk
"""

!pip install torch_geometric --quiet

!pip install torchinfo --quiet

import numpy as np
import networkx as nx
import seaborn as sns
import torch
import random
from torch_geometric.datasets import Planetoid
from torch import nn, optim, Tensor
from torch.nn import functional as F
from torch.utils.data import DataLoader, TensorDataset
from torchinfo import summary
from tqdm.auto import tqdm
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.manifold import TSNE
from torch_geometric.utils import to_dense_adj
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

def set_seed(seed) -> None:
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)

SEED = 42
set_seed(SEED)

def create_graph(
    num_nodes : int,
    num_clusters : int,
    in_proba : float,
    out_proba : float
) -> tuple[np.ndarray,np.ndarray]:

    G = np.zeros((num_nodes,num_nodes), dtype=bool)
    labels = np.random.randint(0,num_clusters,(num_nodes,))

    for i in range(num_clusters):
        for j in range(num_clusters):

            row = labels == i
            col = labels == j
            mask = np.outer(row,col)

            if i == j:
                G = G | (mask & (np.random.rand(*G.shape) < in_proba))
            else:
                G = G | (mask & (np.random.rand(*G.shape) < out_proba))

    G = G.astype(float)

    return G, labels

N = 100
K = 5
p_in = 0.4
p_out = 0.01

G, labels = create_graph(N,K,p_in,p_out)
nx.draw(nx.from_numpy_array(G), node_color=labels, with_labels=True)

def generate_random_walks(
    G : np.ndarray,
    num_walks : int,
    min_walk_length : int,
    max_walk_length : int
) -> list[np.ndarray]:

    walks = []

    indices = np.arange(G.shape[0])

    for _ in tqdm(range(num_walks)):

        start_node = np.random.randint(0, G.shape[0])
        walk = [start_node]

        length = np.random.randint(min_walk_length, max_walk_length)

        for _ in range(length):

            neighbors = indices[G[walk[-1], :] > 0]

            if len(neighbors) == 0:
                break

            walk.append(np.random.choice(neighbors))

        walks.append(np.array(walk).astype(int))

    return walks

walks = generate_random_walks(G, 1000, 5, 12)
print(walks[0].shape)

def window_process(
    walks : list[np.ndarray],
    half_window_size : int
) -> tuple[np.ndarray,np.ndarray]:

    x = []
    y = []

    for walk in tqdm(walks):

        for i, node in enumerate(walk):

            start = max(0, i - half_window_size)
            end = min(len(walk), i + half_window_size + 1)

            for j in range(start, end):

                if i != j:

                    x.append(node)
                    y.append(walk[j])

    x = np.array(x).astype(int)
    y = np.array(y).astype(int)

    return x, y

x, y = window_process(walks, 2)
print(x.shape, y.shape)

class SkipGram(nn.Module):

    def __init__(self, d : int, V : int):
        super(SkipGram, self).__init__()

        self.embedding = nn.Embedding(V, d)
        self.linear = nn.Linear(d, V)

    def forward(self, x : Tensor) -> Tensor:
        return self.linear(self.embedding(x))

    def fit(self,
        x : Tensor,
        y : Tensor,
        batch_size : int,
        epochs : int,
        lr : float,
        device : torch.device = torch.device('cpu')
    ) -> 'SkipGram':

        self.train().to(device)

        optimizer = optim.Adam(self.parameters(), lr=lr)

        dataset = TensorDataset(x, y)
        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

        for epoch in range(epochs):

            running_loss = 0.0

            for x, y in tqdm(loader):

                x = x.to(device)
                y = y.to(device)

                optimizer.zero_grad()
                output = self.forward(x)
                loss = F.cross_entropy(output, y)
                loss.backward()
                optimizer.step()

                running_loss += loss.item() / len(loader)

            print(f'Epoch {epoch+1}/{epochs}, Loss {loss.item()}')

        return self

input_data = torch.tensor(x)
summary(SkipGram(8, N), input_data=input_data)

BATCH_SIZE = 64
EPOCHS = 10
LR = 0.001
D = 8

model = SkipGram(D, N).fit(
    torch.tensor(x),
    torch.tensor(y),
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    lr=LR
)

tsne = Pipeline([
    ('scaler', StandardScaler()),
    ('tsne', TSNE(n_components=2))
])

embeddings = torch.clone(model.embedding.weight.data).detach().cpu().numpy()
print(embeddings.shape)

x1, x2 = tsne.fit_transform(embeddings).transpose()
print(x1.shape, x2.shape)

sns.scatterplot(x=x1, y=x2, hue=labels)

"""====================="""

dataset = Planetoid(root='/tmp/Cora', name='Cora')

print(dataset[0])

y = dataset[0].y
values, counts = torch.unique(y, return_counts=True)

print(f"There are {len(values)} classes in the dataset")

for class_, count in zip(values, counts):
    print(f"Class {class_.item()} has {count.item()} samples")

ax = sns.barplot(x=values.numpy(), y=counts.numpy())
ax.set(xlabel='Class', ylabel='Count')

train_mask = dataset[0].train_mask
val_mask = dataset[0].val_mask
test_mask = dataset[0].test_mask

print(f"Train set has {train_mask.sum().item()} samples")
print(f"Validation set has {val_mask.sum().item()} samples")
print(f"Test set has {test_mask.sum().item()} samples")

G = to_dense_adj(dataset[0].edge_index)[0]
G = G + torch.eye(G.shape[0]) # Enforce self-connections
print(G.shape)

NUM_WALKS = 5 * G.shape[0]
MIN_WALK_LENGTH = 10
MAX_WALK_LENGTH = int(G.shape[0] ** 0.5)

walks = generate_random_walks(G.numpy(), NUM_WALKS, MIN_WALK_LENGTH, MAX_WALK_LENGTH)
print(len(walks))

WINDOW_SIZE = 2
x, y = window_process(walks, WINDOW_SIZE)
print(x.shape, y.shape)

BATCH_SIZE = 256
EPOCHS = 10
LR = 0.001
D = 192
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model = SkipGram(D, G.shape[0]).fit(
    torch.tensor(x),
    torch.tensor(y),
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    lr=LR,
    device=DEVICE
)

embeddings = torch.clone(model.embedding.weight.data).detach().cpu().numpy()
print(embeddings.shape)

dtrain, dtest, ytrain, ytest = train_test_split(embeddings, dataset[0].y.numpy(), test_size=0.2)

print(dtrain.shape, dtest.shape, ytrain.shape, ytest.shape)

svc = Pipeline([
    ('scaler', StandardScaler()),
    ('svc', SVC())
])

svc.fit(dtrain, ytrain)

y_test_pred = svc.predict(dtest)
print(classification_report(ytest, y_test_pred))

cm = confusion_matrix(ytest, y_test_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')